{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "",
  "signature": "sha256:24e011fba977fc2748ba11b72bc6737de21740a50b04a921db2c2fecd2b486f2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<small><i>This notebook was put together by [Abel Meneses](http://www.menesesabad.com) for PyData 2018. Source and license info is on [GitHub](https://github.com/sorice/nlp_pydata2018/).</i></small>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Etiquetado de las Partes del Discurso#\n",
      "**Part of Speech Tagging**\n",
      "\n",
      "[Ver proceso previo: Bases de NLP](#nlp_basic)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Fecha de elaboraci\u00f3n inicial**: agosto de 2015\n",
      "**\u00daltima actualizaci\u00f3n**: 9 de agosto de 2015\n",
      "<a id='indice'></a>\n",
      "##\u00cdndice##\n",
      "\n",
      "1. [Introducci\u00f3n](#introduccion)\n",
      "    - 1.1 [Ejemplo Treebank en Idioma Ingl\u00e9s.](#ejemplo_treebank_ingles) \n",
      "Ejemplo sencillo usando el fragmento del corpus Treebank contenido en NLTK.\n",
      "    - 1.2 [Conjuntos de Etiquetas.](#tag_set)\n",
      "\n",
      "2. [Biblioteca NLTK.](#biblioteca_nltk) Usualmente \u00fatiles para hacer Miner\u00eda de Texto.\n",
      "    - 2.1 [Etiquetado con Unigram](#etiquetador unigram) Etiquetador secuencial.\n",
      "    - 2.2 [Etiquetado con el Stanford-Tagger](#pos_con_stanfordtagger)\n",
      "    - 2.3 [Etiquetador configurable ClassifierBasedPOSTagger](#classifierbasedpostagger)\n",
      "\n",
      "3. [Biblioteca Pattern](#biblioteca_pattern)\n",
      "    - 3.1 [POS con Parse](#pos_con_parse)\n",
      "\n",
      "4. [Playfull and Depper Programaci\u00f3n NLP](#playfull_programming)\n",
      "    - 4.1 [Analizador de similaridad usando POS](#pos_similarity)\n",
      "\n",
      "[Conclusiones](#conclusiones)\n",
      "\n",
      "[Ejercicios](#ejercicios)\n",
      "\n",
      "[Referencias](#referencias)\n",
      "\n",
      "[\u00cdndice Alfab\u00e9tico](#indice_alfabetico)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='introduccion'></a>\n",
      "##Introducci\u00f3n##\n",
      "\n",
      "El procesado de las partes de las partes del discurso es una t\u00e9cnica para extraer en un\n",
      "texto las unidades gramaticales como el sintagma nominal sujeto y las partes de la\n",
      "oraci\u00f3n desde el punto de vista l\u00e9xico, como verbos, etc.\n",
      "\n",
      "Este compendio contiene ejemplos en espa\u00f1ol utilizados en \n",
      "http://www.nltk.org/book/ch05.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='ejemplo_treebank_ingles'></a>\n",
      "##Ejemplo TreeBank Corpus en Ingl\u00e9s##\n",
      "\n",
      "Corpus en ingl\u00e9s para hacer POS Tagging (ver el NLTK Book [Perkins2014](#perkins2014)).\n",
      "\n",
      "Los ejemplos de oraciones etiquetadas, seg\u00fan el etiquetado del Treebank, pueden ser\n",
      "encontradas en la carpeta: *nltk\\_data/corpora/treebank/tagged* .\n",
      "\n",
      "Lo que representa cada etiqueta puede ser encontrado en los materiales de este notebook:\n",
      "[TreeBank Tag Set](files/htmls/3.3/Penn-Treebank_POS_Tagset.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tag import pos_tag \n",
      "from nltk.tokenize import word_tokenize \n",
      "string = ''\n",
      "print('Resultado esperado:')\n",
      "print('(John, NNP),(s,POS),(big,JJ),(idea,NN),(is,VBZ),(bad,JJ)')\n",
      "result =  pos_tag(word_tokenize(\"John's big idea is bad.\"))\n",
      "for i in range(len(result)-1):\n",
      "    string+= '('+result[i][0]+', '+result[i][1]+')'\n",
      "print('Resultado obtenido:')\n",
      "print string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resultado esperado:\n",
        "(John, NNP),(s,POS),(big,JJ),(idea,NN),(is,VBZ),(bad,JJ)\n",
        "Resultado obtenido:\n",
        "(John, NNP)('s, POS)(big, JJ)(idea, NN)(is, VBZ)(bad, JJ)"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En este ejemplo pos_tag que est\u00e1 implementado en el *~/nltk/tag/__init__.py*, utiliza\n",
      "por defecto el modelo del Treebank en ingl\u00e9s. Este fichero es parte del *nltk\\_data* y \n",
      "es *~/taggers/maxent\\_treebank\\_pos\\_tagger/english.pickle*.\n",
      "\n",
      "Evidentemente para POS del idioma espa\u00f1ol este corpus no sirve. Veremos algunas\n",
      "alternativas en las secciones m\u00e1s adelante.\n",
      "\n",
      "Otro ejemplo puede ser utilizando el corpus Brown. No olvide copiar el corpus en la \n",
      "carpeta que ha definido para los datos, en mi caso ~nltk_data/corpora/ ."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
      "train_sents = brown_tagged_sents[:30] #cogiendo solo 30 oraciones.\n",
      "#sacando los tags que se usan aqu\u00ed:\n",
      "list = []\n",
      "for i in range(len(train_sents)):\n",
      "    for j in range(len(train_sents[i])): \n",
      "        if train_sents[i][j][1] not in list:\n",
      "            list.append(train_sents[i][j][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Cantidad de etiquetas usadas',len(list)\n",
      "print 'tagset:',list[:7],'...'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cantidad de etiquetas usadas 68\n",
        "tagset: [u'AT', u'NP-TL', u'NN-TL', u'JJ-TL', u'VBD', u'NR', u'NN'] ..."
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como puede verse en el archivo ~/nltk_data/taggers/universal_tagset/en-brown.map este\n",
      "etiquetado es a\u00fan m\u00e1s complejo que el TreeBank. Su lectura podr\u00eda empezar en \n",
      "http://www.hit.uib.no/icame/brown/bcm.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='tag_set'></a>\n",
      "#Tag Set#\n",
      "\n",
      "Existen muchos tipos de etiquetas POS, ya hemos mencionado TreeBank y Brown. Cada \n",
      "conjunto tiene sus caracter\u00edsticas y su alcance radica en la profundidad del an\u00e1lisis\n",
      "que se hizo de las oraciones. A continuaci\u00f3n exponemos el conjunto llamado universal:\n",
      "\n",
      "- VERB - verbs (all tenses and modes)\n",
      "- NOUN - nouns (common and proper)\n",
      "- PRON - pronouns\n",
      "- ADJ - adjectives\n",
      "- ADV - adverbs\n",
      "- ADP - adpositions (prepositions and postpositions)\n",
      "- CONJ - conjunctions\n",
      "- DET - determiners\n",
      "- NUM - cardinal numbers\n",
      "- PRT - particles or other function words\n",
      "- X - other: foreign words, typos, abbreviations\n",
      "- . - punctuation\n",
      "\n",
      "Leer m\u00e1s en: http://arxiv.org/abs/1104.2086 \n",
      "y http://code.google.com/p/universal-pos-tags/\n",
      "\n",
      "En NLTK 3 existe una funci\u00f3n que puede mapear el brown a este tag set universal. Ver\n",
      "~/nltk/tag/mapping.py\n",
      "Igualmente en el fichero ~/nltk_data/taggers/universal_tagset/en-brown.map aparece la\n",
      "conversi\u00f3n del brown al universal."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='Biblioteca NLTK'></a>\n",
      "#Biblioteca NLTK#\n",
      "\n",
      "<a id='etiquetador unigram'></a>\n",
      "##Etiquetador Unigram##\n",
      "\n",
      "El siguiente ejemlo utiliza un *corpus etiquetado* en espa\u00f1ol elaborado en la\n",
      "Universidad de Barcelona** ver [CESS2007](#cess2007).\n",
      "La esencia de este ejemplo puede se encontrado en \n",
      "[Perkins 2014, *p\u00e1g 89*](#perkins2014).\n",
      "Este etiquetador pertenece a las clases programadas para etiquetar oraciones en el \n",
      "m\u00f3dulo *nltk/tag/sequential.py*\n",
      "\n",
      "Los ejemplos de textos\n",
      "etiquetados pueden encontrarse en la ruta *nltk\\_data/corpora/cess\\_es*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from nltk.corpus import cess_esp as cess\n",
      "from nltk import UnigramTagger as ut\n",
      "from nltk import BigramTagger as bt\n",
      "\n",
      "# Read the corpus into a list, \n",
      "# each entry in the list is one sentence.\n",
      "cess_sents = cess.tagged_sents()\n",
      "\n",
      "# Train the unigram tagger\n",
      "uni_tag = ut(cess_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "sentence = \"Hoy com\u00ed en casa de Lola.\"\n",
      "\n",
      "# Tagger reads a list of tokens.\n",
      "uni_tag.tag(sentence.split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[('Hoy', 'rg'),\n",
        " ('com\u00ed', None),\n",
        " ('en', 'sps00'),\n",
        " ('casa', 'ncfs000'),\n",
        " ('de', 'sps00'),\n",
        " ('Lola.', None)]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En este primer ejemplo no reconoce el verbo.\n",
      "El problema fundamental al que se enfrentan los programadores\n",
      "es que generalmente todo funciona bien para ingl\u00e9s. Cuando intentamos programar algo\n",
      "para procesar el idioma espa\u00f1ol, comienzan las dificultades con las t\u00edldes y las \u00f1.\n",
      "\n",
      "En los ejemplos, para procesar espa\u00f1ol, que veremos m\u00e1s adelante resolveremos este\n",
      "problema. For more details see the next offline [full example](files/htmls/3.3/Dive_Into_NLTK,_Part_III-_Part-Of-Speech_Tagging_and_POS_Tag/index.html)\n",
      "\n",
      "**Nota:** el corpus *cess* utiliza el etiquetado \n",
      "[EAGLES](http://nlp.lsi.upc.edu/freeling/doc/tagsets/tagset-es.html) que es muy\n",
      "profesional y a la vez complejo. Por ello hemos introducido en los materiales de este\n",
      "notebook una copia de su explicaci\u00f3n para que pueda ser utilizada offline:\n",
      "[EAGLES Tag Set](files/htmls/3.3/EAGLES_tagset/index.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='pos_con_stanfordtagger'></a>\n",
      "## POS con Stanford Tagger\n",
      "\n",
      "[Este ejemplo](files/htmls/3.3/python_-_Stanford_Parser_and_NLTK_-_Stack_Overflow/index.html) fue tomado en su versi\u00f3n original de una \n",
      "[URL en Stackoverflow](http://stackoverflow.com/questions/14732465/nltk-tagging-spanish-words-using-a-corpus)\n",
      "\n",
      "El ejemplo utiliza el etiquetador de la Universidad de Stanford\n",
      "una de las m\u00e1s avanzadas en el campo de NLP.\n",
      "</br>**ver etiquetador** http://nlp.stanford.edu/software/tagger.shtml \n",
      "\n",
      "Tambi\u00e9n se utiliza el conjunto de etiquetas de la API *FreeLing*, la m\u00e1s avanzada en\n",
      "el procesamiento del idioma espa\u00f1ol. Mantenida adem\u00e1s por la *Universitat Polit\u00e8cnica \n",
      "de Catalunya*\n",
      "</br>**ver conjunto de etiquetas**: http://nlp.lsi.upc.edu/freeling/doc/tagsets/tagset-es.html or [In here FreeLing-Stanford Tagset](files/htmls/3.3/Freeling-Stanford_Parser_tagset-es.html). Veamos un ejemplo funcional y luego los detalles de como ejecutarlo en tu PC con el menor grado de dificultad."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.parse.stanford import StanfordParser\n",
      "from nltk.parse.stanford import StanfordDependencyParser\n",
      "from nltk.parse.stanford import StanfordNeuralDependencyParser\n",
      "from nltk.tag.stanford import StanfordPOSTagger, StanfordNERTagger\n",
      "from nltk.tokenize.stanford import StanfordTokenizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_pos_dir = '/opt/stanford/stanford-postagger-full-2015-04-20/'\n",
      "eng_model_filename= stanford_pos_dir + 'models/english-left3words-distsim.tagger'\n",
      "my_path_to_jar= stanford_pos_dir + 'stanford-postagger.jar'\n",
      "st = StanfordPOSTagger(model_filename=eng_model_filename, path_to_jar=my_path_to_jar) \n",
      "st.tag('What is the airspeed of an unladen swallow ?'.split())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[('What', 'WP'),\n",
        " ('is', 'VBZ'),\n",
        " ('the', 'DT'),\n",
        " ('airspeed', 'NN'),\n",
        " ('of', 'IN'),\n",
        " ('an', 'DT'),\n",
        " ('unladen', 'JJ'),\n",
        " ('swallow', 'VB'),\n",
        " ('?', '.')]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Nota:** Un detalle importante es que las oraciones que se etiquetan deben tener los signos de puntuaci\u00f3n separados. Como se ver\u00e1 m\u00e1s adelante Pattern s\u00ed los identifica."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "es_model_filename= stanford_pos_dir + 'models/spanish.tagger'\n",
      "spanish_postagger = StanfordPOSTagger(model_filename=es_model_filename, path_to_jar=my_path_to_jar, encoding='utf8')\n",
      "\n",
      "sentences = ['El copal se usa principalmente para sahumar en distintas'\n",
      "             + 'ocasiones como lo son las fiestas religiosas.','Las flores, '\n",
      "             + 'hojas y frutos se usan para aliviar la tos y tambi\u00e9n se emplea'\n",
      "             + 'como sedante.']\n",
      "\n",
      "sentences = ['Hoy com\u00ed en casa de Lola.']\n",
      "\n",
      "spanish_postagger.tag(sentences)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[('Hoy', 'rg'),\n",
        " ('com\u00ed', 'vmis000'),\n",
        " ('en', 'sp000'),\n",
        " ('casa', 'nc0s000'),\n",
        " ('de', 'sp000'),\n",
        " ('Lola.', 'np00000')]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(sentences)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['El copal se usa principalmente para sahumar en distintasocasiones como lo son las fiestas religiosas.', 'Las flores, hojas y frutos se usan para aliviar la tos y tambi\u00e9n se empleacomo sedante.']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent in sentences:\n",
      "    tagged_words = spanish_postagger.tag(sent.split())\n",
      "    #print (tagged_words)\n",
      "    nouns = []\n",
      "\n",
      "    for (word, tag) in tagged_words:\n",
      "        #print(word+' '+tag)\n",
      "        if tag.startswith('n'): nouns.append(word)\n",
      "\n",
      "    print(nouns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['casa', 'Lola.']\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Copie el Stanford-Postager.jar en la carpeta donde est\u00e1 realizando sus experimentos.\n",
      "Adicione una carpeta *models* y dentro el modelo del lenguaje que va a parsear.\n",
      "\n",
      "(opcional) Algunas soluciones utilizan directamente los modelos, para ello descompacte el .jar de los modelos, y luego col\u00f3quelos en su carpeta de trabajo STANFORD_MODELS_DIR:\n",
      "<html>\n",
      "<br><blockquote>\\$> unzip stanford-corenlp-3.7.0-models.jar<br>\n",
      "\\$> mv edu/stanford/nlp/models/ STANFORD_MODELS_DIR</blockquote>\n",
      "</html>\n",
      "\n",
      "Se debe tener cuidado con las versiones de ambos proyectos (NLTK y el Stanford-Tagger o\n",
      "Stanford-Parser) pues como son proyectos en constante desarrollo cambian rapidamente.\n",
      "Este notebook est\u00e1 configurado para usar los sigtes paquetes\n",
      "\n",
      "* http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip\n",
      "* http://nlp.stanford.edu/software/stanford-postagger-full-2015-04-20.zip\n",
      "* http://nlp.stanford.edu/software/stanford-parser-full-2015-04-20.zip\n",
      "* versi\u00f3n 3.1 de NLTK https://pypi.python.org/pypi/nltk\n",
      "\n",
      "**Notes:** \n",
      "\n",
      "<html><ul>\n",
      "<li>En Ubuntu GNU/Linux se recomienda usar a partir del LTS 16.04 pues es stanford-tools ha sido desarrollada para para la la versi\u00f3n 1.8 de java del openJDK pues esta versi\u00f3n del   esta versi\u00f3n de java o superior. En Windows utilizar Python3.4 as\u00ed como las versiones de 32bits pues hay algunos bugs importantes en la versi\u00f3n de 64bits (al menos hasta el 15 de enero de 2016).\n",
      "\n",
      "<li>Al final si se intenta con java 1.7, nltk 3.0.3 y el stanford-tagger-2015-04-20 da este error al ejecutar \"javac -cp stanford-tagger.jar TaggerDemo.java\":<br>\n",
      "\n",
      "<p><code>*TaggerDemo.java:6: cannot access edu.stanford.nlp.ling.Sentence... \n",
      "class file has wrong version 52.0, should be 50.0*</code>\n",
      "</html>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='classifierbasedpostagger'></a>\n",
      "##Etiquetador configurable ClassifierBasedPOSTagger de NLTK##\n",
      "\n",
      "Este etiquetador es parametrizable con clasificadores que ya tenemos. Inicialmente\n",
      "podemos decir que devuelve las palabras etiquetadas con POS(no sabr\u00eda decir a\u00fan)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import treebank\n",
      "train_sents = treebank.tagged_sents()[:50]\n",
      "test_sents = treebank.tagged_sents()[51:101]\n",
      "\n",
      "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
      "from nltk.classify import MaxentClassifier\n",
      "me_tagger = ClassifierBasedPOSTagger(train=train_sents,classifier_builder=MaxentClassifier.train)\n",
      "me_tagger.evaluate(test_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  ==> Training (100 iterations)\n",
        "\n",
        "      Iteration    Log Likelihood    Accuracy\n",
        "      ---------------------------------------\n",
        "             1          -3.55535        0.006\n",
        "             2          -0.90550        0.970\n",
        "             3          -0.55974        0.999\n",
        "             4          -0.40216        1.000\n",
        "             5          -0.31346        1.000\n",
        "             6          -0.25672        1.000\n",
        "             7          -0.21736        1.000\n",
        "             8          -0.18847        1.000\n",
        "             9          -0.16636        1.000\n",
        "      Training stopped: keyboard interrupt\n",
        "         Final          -0.16636        1.000"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.7685025817555938"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**OJO:** Si la corrida demora, apriete el bot\u00f3n interrupt del notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "me_tagger.tag(['I','run','for','the','beach'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[('I', u'DT'),\n",
        " ('run', u'NN'),\n",
        " ('for', u'IN'),\n",
        " ('the', u'DT'),\n",
        " ('beach', u'NN')]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como se pude observar, para idioma ingl\u00e9s, este m\u00e9todo etiqueta correctamente el 76% de\n",
      "los casos. En el libro se documenta que tras probar con unas 3000 oraciones la\n",
      "eficiencia de este algoritmo rebasa el 93%. Aqu\u00ed solo se ha entrenado con 50 oraciones\n",
      "por problemas de rendimiento."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='biblioteca_pattern'></a>\n",
      "##Biblioteca Pattern##\n",
      "\n",
      "<a id='pos_con_parse'></a>\n",
      "##POS con Parse##\n",
      "\n",
      "El cuarto ejemplo est\u00e1 dedicado a introducir m\u00e1s formalmente la biblioteca belga\n",
      "**Pattern**. En este caso su m\u00f3dulo para hacer POS en idioma espa\u00f1ol. Como pudo verse\n",
      "en el ejemplo en ingl\u00e9s vs espa\u00f1ol hecho con NLTK, la implementaci\u00f3n de estas funciones\n",
      "para ambos idiomas son diferentes. Sin embargo en *Pattern* la implementaci\u00f3n es \n",
      "similar.\n",
      "\n",
      "La ayuda para esta biblioteca puede ser encontrada online en \n",
      "[online Pattern](http://www.clips.ua.ac.be/pages/pattern).\n",
      "\n",
      "**Note:** Pattern library is only available on Python2. Any further problem with this section must be corrected running the notebook on Ipython2."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pattern.en import parse, pprint\n",
      "en = 'Jonh saw the fish'\n",
      "en = parse(en, relations=True, lemmata=True)\n",
      "pprint(en)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA   \n",
        "                                                             \n",
        "          Jonh   NNP    NP      SBJ    1      -      jonh    \n",
        "           saw   VBD    VP      -      1      -      saw     \n",
        "           the   DT     NP      OBJ    1      -      the     \n",
        "          fish   NN     NP ^    OBJ    1      -      fish    "
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pattern.es import parse, pprint\n",
      "es = 'El estudiante comi\u00f3 el pescado de su profesor demasiado tarde.'\n",
      "es = parse(es, relations=True, lemmata=True)\n",
      "pprint(es)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA        \n",
        "                                                                  \n",
        "            El   DT     NP      SBJ    1      -      el           \n",
        "    estudiante   NN     NP ^    SBJ    1      -      estudiante   \n",
        "         comi\u00f3   VB     VP      -      1      -      comer        \n",
        "            el   DT     NP      OBJ    1      -      el           \n",
        "       pescado   NN     NP ^    OBJ    1      -      pescado      \n",
        "            de   IN     PP      -      -      PNP    de           \n",
        "            su   PRP$   NP      -      -      PNP    su           \n",
        "      profesor   NN     NP ^    -      -      PNP    profesor     \n",
        "     demasiado   RB     NP ^    -      -      PNP    demasiado    \n",
        "         tarde   RB     NP ^    -      -      PNP    tarde        \n",
        "             .   .      -       -      -      -      .            "
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(es)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "en.parser.TaggedString"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como se puede observar el objeto *\"es\"* es del tipo *TaggedString*. \n",
      "\n",
      "Cuando se revisa\n",
      "el c\u00f3digo del *pattern/text/es/parser/\\_\\_init\\_\\_.py* se puede comprobar que el \n",
      "**Parole Tag** es convertido a **Treebank Tag**. La presici\u00f3n de este algoritmo de\n",
      "pattern es de alrededor del 92% seg\u00fan el propio fichero, pero la conversi\u00f3n de Parole a\n",
      "Treebank puede incurrir en problemas adicionales.\n",
      "\n",
      "**Manipulemos el objeto \"es\"**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test=es.split()\n",
      "newtest = []\n",
      "\n",
      "for i in test[0]:\n",
      "    newtest.append(i)\n",
      "\n",
      "print newtest[2]\n",
      "print test[0][2][0].encode('utf8')+\" -> \"+test[0][0][1].encode('utf8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'comi\\xf3', u'VB', u'B-VP', u'O', u'VP-1', u'comer']\n",
        "comi\u00f3 -> DT"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='conclusiones'></a>\n",
      "\n",
      "##Conclusiones##\n",
      "- El POS..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='ejercicios'></a>\n",
      "\n",
      "##Ejercicios##\n",
      "\n",
      "* **Ejercicio 1:** Implemente un POS en espa\u00f1ol utilizando un clasificador..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='references'></a>\n",
      "##Referencias##\n",
      "\n",
      "* <a id='perkins2014'></a>**[Perkins2014]** Jacob Perkins, *Python 3 Text Processing with NLTK 3 Cookbook*, 2014. \n",
      "Cap\u00edtulo 5 *Part-of-speech Tagging*\n",
      "\n",
      "* <a id='cess2007'></a>**[CESS2007]** Antonia Mart\u00ed, Mariona Taul\u00e9, Llu\u00eds M\u00e1rquez, Manuel Bertran. 2007. \n",
      "CESS-ECE: A Multilingual and Multilevel Annotated Corpus. \n",
      "*see* http://www.lsi.upc.edu/~mbertran/cess-ece/publications\n",
      "\n",
      "* **NLTK** Bird, Steven, Edward Loper and Ewan Klein (2009), Natural \n",
      "Language Processing with Python. O\u2019Reilly Media Inc. *see* http://nltk.org/\n",
      "\n",
      "* (colocar referencias al Pen Treebank POS Tags Set)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='alphabetic_index'></a>\n",
      "##\u00cdndice Alfab\u00e9tico##\n",
      "\n",
      "<a id='token'></a>\n",
      "**Token**: se\u00f1al, indicio, muestra. Se usa generalmente para referirse a la unidad\n",
      "m\u00e1s peque\u00f1a de procesamiento: palabras, fonemas, n-grams, etc..\n",
      "\n",
      "\n",
      "Volver al [*\u00cdndice*](#indice)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}