{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This notebook was put together by [Abel Meneses](http://www.menesesabad.com) for PyData 2018. Source and license info is on [GitHub](https://github.com/sorice/nlp_pydata2018/).</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Etiquetado de las Partes del Discurso#\n",
    "**Part of Speech Tagging**\n",
    "\n",
    "[Ver proceso previo: Bases de NLP](#nlp_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fecha de elaboración inicial**: agosto de 2015\n",
    "**Última actualización**: 9 de agosto de 2015\n",
    "<a id='indice'></a>\n",
    "##Índice##\n",
    "\n",
    "1. [Introducción](#introduccion)\n",
    "    - 1.1 [Ejemplo Treebank en Idioma Inglés.](#ejemplo_treebank_ingles) \n",
    "Ejemplo sencillo usando el fragmento del corpus Treebank contenido en NLTK.\n",
    "    - 1.2 [Conjuntos de Etiquetas.](#tag_set)\n",
    "\n",
    "2. [Biblioteca NLTK.](#biblioteca_nltk) Usualmente útiles para hacer Minería de Texto.\n",
    "    - 2.1 [Etiquetado con Unigram](#etiquetador unigram) Etiquetador secuencial.\n",
    "    - 2.2 [Etiquetado con el Stanford-Tagger](#pos_con_stanfordtagger)\n",
    "    - 2.3 [Etiquetador configurable ClassifierBasedPOSTagger](#classifierbasedpostagger)\n",
    "\n",
    "3. [Biblioteca Pattern](#biblioteca_pattern)\n",
    "    - 3.1 [POS con Parse](#pos_con_parse)\n",
    "\n",
    "4. [Playfull and Depper Programación NLP](#playfull_programming)\n",
    "    - 4.1 [Analizador de similaridad usando POS](#pos_similarity)\n",
    "\n",
    "[Conclusiones](#conclusiones)\n",
    "\n",
    "[Ejercicios](#ejercicios)\n",
    "\n",
    "[Referencias](#referencias)\n",
    "\n",
    "[Índice Alfabético](#indice_alfabetico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduccion'></a>\n",
    "##Introducción##\n",
    "\n",
    "El procesado de las partes de las partes del discurso es una técnica para extraer en un\n",
    "texto las unidades gramaticales como el sintagma nominal sujeto y las partes de la\n",
    "oración desde el punto de vista léxico, como verbos, etc.\n",
    "\n",
    "Este compendio contiene ejemplos en español utilizados en \n",
    "http://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ejemplo_treebank_ingles'></a>\n",
    "## Ejemplo TreeBank Corpus en Inglés\n",
    "\n",
    "Corpus en inglés para hacer POS Tagging (ver el NLTK Book [Perkins2014](#perkins2014)).\n",
    "\n",
    "Los ejemplos de oraciones etiquetadas, según el etiquetado del Treebank, pueden ser\n",
    "encontradas en la carpeta: *nltk\\_data/corpora/treebank/tagged* .\n",
    "\n",
    "Lo que representa cada etiqueta puede ser encontrado en los materiales de este notebook:\n",
    "[TreeBank Tag Set](files/htmls/3.3/Penn-Treebank_POS_Tagset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado esperado:\n",
      "(John, NNP),(s,POS),(big,JJ),(idea,NN),(is,VBZ),(bad,JJ)\n",
      "Resultado obtenido:\n",
      "(John, NNP)('s, POS)(big, JJ)(idea, NN)(is, VBZ)(bad, JJ)"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag \n",
    "from nltk.tokenize import word_tokenize \n",
    "string = ''\n",
    "print('Resultado esperado:')\n",
    "print('(John, NNP),(s,POS),(big,JJ),(idea,NN),(is,VBZ),(bad,JJ)')\n",
    "result =  pos_tag(word_tokenize(\"John's big idea is bad.\"))\n",
    "for i in range(len(result)-1):\n",
    "    string+= '('+result[i][0]+', '+result[i][1]+')'\n",
    "print('Resultado obtenido:')\n",
    "print string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo pos_tag que está implementado en el *~/nltk/tag/__init__.py*, utiliza\n",
    "por defecto el modelo del Treebank en inglés. Este fichero es parte del *nltk\\_data* y \n",
    "es *~/taggers/maxent\\_treebank\\_pos\\_tagger/english.pickle*.\n",
    "\n",
    "Evidentemente para POS del idioma español este corpus no sirve. Veremos algunas\n",
    "alternativas en las secciones más adelante.\n",
    "\n",
    "Otro ejemplo puede ser utilizando el corpus Brown. No olvide copiar el corpus en la \n",
    "carpeta que ha definido para los datos, en mi caso ~nltk_data/corpora/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "train_sents = brown_tagged_sents[:30] #cogiendo solo 30 oraciones.\n",
    "#sacando los tags que se usan aquí:\n",
    "list = []\n",
    "for i in range(len(train_sents)):\n",
    "    for j in range(len(train_sents[i])): \n",
    "        if train_sents[i][j][1] not in list:\n",
    "            list.append(train_sents[i][j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de etiquetas usadas 68\n",
      "tagset: [u'AT', u'NP-TL', u'NN-TL', u'JJ-TL', u'VBD', u'NR', u'NN'] ..."
     ]
    }
   ],
   "source": [
    "print 'Cantidad de etiquetas usadas',len(list)\n",
    "print 'tagset:',list[:7],'...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede verse en el archivo ~/nltk_data/taggers/universal_tagset/en-brown.map este\n",
    "etiquetado es aún más complejo que el TreeBank. Su lectura podría empezar en \n",
    "http://www.hit.uib.no/icame/brown/bcm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tag_set'></a>\n",
    "# Tag Set\n",
    "\n",
    "Existen muchos tipos de etiquetas POS, ya hemos mencionado TreeBank y Brown. Cada \n",
    "conjunto tiene sus características y su alcance radica en la profundidad del análisis\n",
    "que se hizo de las oraciones. A continuación exponemos el conjunto llamado universal:\n",
    "\n",
    "- VERB - verbs (all tenses and modes)\n",
    "- NOUN - nouns (common and proper)\n",
    "- PRON - pronouns\n",
    "- ADJ - adjectives\n",
    "- ADV - adverbs\n",
    "- ADP - adpositions (prepositions and postpositions)\n",
    "- CONJ - conjunctions\n",
    "- DET - determiners\n",
    "- NUM - cardinal numbers\n",
    "- PRT - particles or other function words\n",
    "- X - other: foreign words, typos, abbreviations\n",
    "- . - punctuation\n",
    "\n",
    "Leer más en: http://arxiv.org/abs/1104.2086 \n",
    "y http://code.google.com/p/universal-pos-tags/\n",
    "\n",
    "En NLTK 3 existe una función que puede mapear el brown a este tag set universal. Ver\n",
    "~/nltk/tag/mapping.py\n",
    "Igualmente en el fichero ~/nltk_data/taggers/universal_tagset/en-brown.map aparece la\n",
    "conversión del brown al universal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Biblioteca NLTK'></a>\n",
    "# Biblioteca NLTK\n",
    "\n",
    "<a id='etiquetador unigram'></a>\n",
    "## Etiquetador Unigram\n",
    "\n",
    "El siguiente ejemlo utiliza un *corpus etiquetado* en español elaborado en la\n",
    "Universidad de Barcelona** ver [CESS2007](#cess2007).\n",
    "La esencia de este ejemplo puede se encontrado en \n",
    "[Perkins 2014, *pág 89*](#perkins2014).\n",
    "Este etiquetador pertenece a las clases programadas para etiquetar oraciones en el \n",
    "módulo *nltk/tag/sequential.py*\n",
    "\n",
    "Los ejemplos de textos\n",
    "etiquetados pueden encontrarse en la ruta *nltk\\_data/corpora/cess\\_es*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import cess_esp as cess\n",
    "from nltk import UnigramTagger as ut\n",
    "from nltk import BigramTagger as bt\n",
    "\n",
    "# Read the corpus into a list, \n",
    "# each entry in the list is one sentence.\n",
    "cess_sents = cess.tagged_sents()\n",
    "\n",
    "# Train the unigram tagger\n",
    "uni_tag = ut(cess_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hoy', 'rg'),\n",
       " ('comí', None),\n",
       " ('en', 'sps00'),\n",
       " ('casa', 'ncfs000'),\n",
       " ('de', 'sps00'),\n",
       " ('Lola.', None)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "sentence = \"Hoy comí en casa de Lola.\"\n",
    "\n",
    "# Tagger reads a list of tokens.\n",
    "uni_tag.tag(sentence.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este primer ejemplo no reconoce el verbo.\n",
    "El problema fundamental al que se enfrentan los programadores\n",
    "es que generalmente todo funciona bien para inglés. Cuando intentamos programar algo\n",
    "para procesar el idioma español, comienzan las dificultades con las tíldes y las ñ.\n",
    "\n",
    "En los ejemplos, para procesar español, que veremos más adelante resolveremos este\n",
    "problema. For more details see the next offline [full example](files/htmls/3.3/Dive_Into_NLTK,_Part_III-_Part-Of-Speech_Tagging_and_POS_Tag/index.html)\n",
    "\n",
    "**Nota:** el corpus *cess* utiliza el etiquetado \n",
    "[EAGLES](http://nlp.lsi.upc.edu/freeling/doc/tagsets/tagset-es.html) que es muy\n",
    "profesional y a la vez complejo. Por ello hemos introducido en los materiales de este\n",
    "notebook una copia de su explicación para que pueda ser utilizada offline:\n",
    "[EAGLES Tag Set](files/htmls/3.3/EAGLES_tagset/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volver al [*Índice*](#indice).\n",
    "\n",
    "<a id='pos_con_stanfordtagger'></a>\n",
    "## POS con Stanford Tagger\n",
    "\n",
    "[Este ejemplo](files/htmls/3.3/python_-_Stanford_Parser_and_NLTK_-_Stack_Overflow/index.html) fue tomado en su versión original de una \n",
    "[URL en Stackoverflow](http://stackoverflow.com/questions/14732465/nltk-tagging-spanish-words-using-a-corpus)\n",
    "\n",
    "El ejemplo utiliza el etiquetador de la Universidad de Stanford\n",
    "una de las más avanzadas en el campo de NLP.\n",
    "</br>**ver etiquetador** http://nlp.stanford.edu/software/tagger.shtml \n",
    "\n",
    "También se utiliza el conjunto de etiquetas de la API *FreeLing*, la más avanzada en\n",
    "el procesamiento del idioma español. Mantenida además por la *Universitat Politècnica \n",
    "de Catalunya*\n",
    "</br>**ver conjunto de etiquetas**: http://nlp.lsi.upc.edu/freeling/doc/tagsets/tagset-es.html or [In here FreeLing-Stanford Tagset](files/htmls/3.3/Freeling-Stanford_Parser_tagset-es.html). Veamos un ejemplo funcional y luego los detalles de como ejecutarlo en tu PC con el menor grado de dificultad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "from nltk.parse.stanford import StanfordNeuralDependencyParser\n",
    "from nltk.tag.stanford import StanfordPOSTagger, StanfordNERTagger\n",
    "from nltk.tokenize.stanford import StanfordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('airspeed', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('unladen', 'JJ'),\n",
       " ('swallow', 'VB'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford_pos_dir = '/opt/stanford/stanford-postagger-full-2015-04-20/'\n",
    "eng_model_filename= stanford_pos_dir + 'models/english-left3words-distsim.tagger'\n",
    "my_path_to_jar= stanford_pos_dir + 'stanford-postagger.jar'\n",
    "st = StanfordPOSTagger(model_filename=eng_model_filename, path_to_jar=my_path_to_jar) \n",
    "st.tag('What is the airspeed of an unladen swallow ?'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Un detalle importante es que las oraciones que se etiquetan deben tener los signos de puntuación separados. Como se verá más adelante Pattern sí los identifica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hoy', 'rg'),\n",
       " ('comí', 'vmis000'),\n",
       " ('en', 'sp000'),\n",
       " ('casa', 'nc0s000'),\n",
       " ('de', 'sp000'),\n",
       " ('Lola.', 'np00000')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_model_filename= stanford_pos_dir + 'models/spanish.tagger'\n",
    "spanish_postagger = StanfordPOSTagger(model_filename=es_model_filename, path_to_jar=my_path_to_jar, encoding='utf8')\n",
    "\n",
    "sentences = ['El copal se usa principalmente para sahumar en distintas'\n",
    "             + 'ocasiones como lo son las fiestas religiosas.','Las flores, '\n",
    "             + 'hojas y frutos se usan para aliviar la tos y también se emplea'\n",
    "             + 'como sedante.']\n",
    "\n",
    "sentences = ['Hoy comí en casa de Lola.']\n",
    "\n",
    "spanish_postagger.tag(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El copal se usa principalmente para sahumar en distintasocasiones como lo son las fiestas religiosas.', 'Las flores, hojas y frutos se usan para aliviar la tos y también se empleacomo sedante.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casa', 'Lola.']\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    tagged_words = spanish_postagger.tag(sent.split())\n",
    "    #print (tagged_words)\n",
    "    nouns = []\n",
    "\n",
    "    for (word, tag) in tagged_words:\n",
    "        #print(word+' '+tag)\n",
    "        if tag.startswith('n'): nouns.append(word)\n",
    "\n",
    "    print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copie el Stanford-Postager.jar en la carpeta donde está realizando sus experimentos.\n",
    "Adicione una carpeta *models* y dentro el modelo del lenguaje que va a parsear.\n",
    "\n",
    "(opcional) Algunas soluciones utilizan directamente los modelos, para ello descompacte el .jar de los modelos, y luego colóquelos en su carpeta de trabajo STANFORD_MODELS_DIR:\n",
    "<html>\n",
    "<br><blockquote>\\$> unzip stanford-corenlp-3.7.0-models.jar<br>\n",
    "\\$> mv edu/stanford/nlp/models/ STANFORD_MODELS_DIR</blockquote>\n",
    "</html>\n",
    "\n",
    "Se debe tener cuidado con las versiones de ambos proyectos (NLTK y el Stanford-Tagger o\n",
    "Stanford-Parser) pues como son proyectos en constante desarrollo cambian rapidamente.\n",
    "Este notebook está configurado para usar los sigtes paquetes\n",
    "\n",
    "* http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip\n",
    "* http://nlp.stanford.edu/software/stanford-postagger-full-2015-04-20.zip\n",
    "* http://nlp.stanford.edu/software/stanford-parser-full-2015-04-20.zip\n",
    "* versión 3.1 de NLTK https://pypi.python.org/pypi/nltk\n",
    "\n",
    "**Notes:** \n",
    "\n",
    "<html><ul>\n",
    "<li>En Ubuntu GNU/Linux se recomienda usar a partir del LTS 16.04 pues es stanford-tools ha sido desarrollada para para la la versión 1.8 de java del openJDK pues esta versión del   esta versión de java o superior. En Windows utilizar Python3.4 así como las versiones de 32bits pues hay algunos bugs importantes en la versión de 64bits (al menos hasta el 15 de enero de 2016).\n",
    "\n",
    "<li>Al final si se intenta con java 1.7, nltk 3.0.3 y el stanford-tagger-2015-04-20 da este error al ejecutar \"javac -cp stanford-tagger.jar TaggerDemo.java\":<br>\n",
    "\n",
    "<p><code>*TaggerDemo.java:6: cannot access edu.stanford.nlp.ling.Sentence... \n",
    "class file has wrong version 52.0, should be 50.0*</code>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volver al [*Índice*](#indice).\n",
    "\n",
    "<a id='classifierbasedpostagger'></a>\n",
    "## Etiquetador configurable ClassifierBasedPOSTagger de NLTK\n",
    "\n",
    "Este etiquetador es parametrizable con clasificadores que ya tenemos. Inicialmente\n",
    "podemos decir que devuelve las palabras etiquetadas con POS(no sabría decir aún)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -3.55535        0.006\n",
      "             2          -0.90550        0.970\n",
      "             3          -0.55974        0.999\n",
      "             4          -0.40216        1.000\n",
      "             5          -0.31346        1.000\n",
      "             6          -0.25672        1.000\n",
      "             7          -0.21736        1.000\n",
      "             8          -0.18847        1.000\n",
      "             9          -0.16636        1.000\n",
      "      Training stopped: keyboard interrupt\n",
      "         Final          -0.16636        1.000"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7685025817555938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:50]\n",
    "test_sents = treebank.tagged_sents()[51:101]\n",
    "\n",
    "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
    "from nltk.classify import MaxentClassifier\n",
    "me_tagger = ClassifierBasedPOSTagger(train=train_sents,classifier_builder=MaxentClassifier.train)\n",
    "me_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO:** Si la corrida demora, apriete el botón interrupt del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', u'DT'),\n",
       " ('run', u'NN'),\n",
       " ('for', u'IN'),\n",
       " ('the', u'DT'),\n",
       " ('beach', u'NN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_tagger.tag(['I','run','for','the','beach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se pude observar, para idioma inglés, este método etiqueta correctamente el 76% de\n",
    "los casos. En el libro se documenta que tras probar con unas 3000 oraciones la\n",
    "eficiencia de este algoritmo rebasa el 93%. Aquí solo se ha entrenado con 50 oraciones\n",
    "por problemas de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volver al [*Índice*](#indice).\n",
    "\n",
    "<a id='biblioteca_pattern'></a>\n",
    "## Biblioteca Pattern\n",
    "\n",
    "<a id='pos_con_parse'></a>\n",
    "## POS con Parse\n",
    "\n",
    "El cuarto ejemplo está dedicado a introducir más formalmente la biblioteca belga\n",
    "**Pattern**. En este caso su módulo para hacer POS en idioma español. Como pudo verse\n",
    "en el ejemplo en inglés vs español hecho con NLTK, la implementación de estas funciones\n",
    "para ambos idiomas son diferentes. Sin embargo en *Pattern* la implementación es \n",
    "similar.\n",
    "\n",
    "La ayuda para esta biblioteca puede ser encontrada online en \n",
    "[online Pattern](http://www.clips.ua.ac.be/pages/pattern).\n",
    "\n",
    "**Note:** Pattern library is only available on Python2. Any further problem with this section must be corrected running the notebook on Ipython2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA   \n",
      "                                                             \n",
      "          Jonh   NNP    NP      SBJ    1      -      jonh    \n",
      "           saw   VBD    VP      -      1      -      saw     \n",
      "           the   DT     NP      OBJ    1      -      the     \n",
      "          fish   NN     NP ^    OBJ    1      -      fish    "
     ]
    }
   ],
   "source": [
    "from pattern.en import parse, pprint\n",
    "en = 'Jonh saw the fish'\n",
    "en = parse(en, relations=True, lemmata=True)\n",
    "pprint(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA        \n",
      "                                                                  \n",
      "            El   DT     NP      SBJ    1      -      el           \n",
      "    estudiante   NN     NP ^    SBJ    1      -      estudiante   \n",
      "         comió   VB     VP      -      1      -      comer        \n",
      "            el   DT     NP      OBJ    1      -      el           \n",
      "       pescado   NN     NP ^    OBJ    1      -      pescado      \n",
      "            de   IN     PP      -      -      PNP    de           \n",
      "            su   PRP$   NP      -      -      PNP    su           \n",
      "      profesor   NN     NP ^    -      -      PNP    profesor     \n",
      "     demasiado   RB     NP ^    -      -      PNP    demasiado    \n",
      "         tarde   RB     NP ^    -      -      PNP    tarde        \n",
      "             .   .      -       -      -      -      .            "
     ]
    }
   ],
   "source": [
    "from pattern.es import parse, pprint\n",
    "es = 'El estudiante comió el pescado de su profesor demasiado tarde.'\n",
    "es = parse(es, relations=True, lemmata=True)\n",
    "pprint(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en.parser.TaggedString"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar el objeto *\"es\"* es del tipo *TaggedString*. \n",
    "\n",
    "Cuando se revisa\n",
    "el código del *pattern/text/es/parser/\\_\\_init\\_\\_.py* se puede comprobar que el \n",
    "**Parole Tag** es convertido a **Treebank Tag**. La presición de este algoritmo de\n",
    "pattern es de alrededor del 92% según el propio fichero, pero la conversión de Parole a\n",
    "Treebank puede incurrir en problemas adicionales.\n",
    "\n",
    "**Manipulemos el objeto \"es\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'comi\\xf3', u'VB', u'B-VP', u'O', u'VP-1', u'comer']\n",
      "comió -> DT"
     ]
    }
   ],
   "source": [
    "test=es.split()\n",
    "newtest = []\n",
    "\n",
    "for i in test[0]:\n",
    "    newtest.append(i)\n",
    "\n",
    "print newtest[2]\n",
    "print test[0][2][0].encode('utf8')+\" -> \"+test[0][0][1].encode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volver al [*Índice*](#indice).\n",
    "\n",
    "<a id='conclusiones'></a>\n",
    "\n",
    "## Conclusiones\n",
    "- El POS..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volver al [*Índice*](#indice).\n",
    "\n",
    "<a id='ejercicios'></a>\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "* **Ejercicio 1:** Implemente un POS en español utilizando un clasificador..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volver al [*Índice*](#indice).\n",
    "\n",
    "<a id='references'></a>\n",
    "## Referencias\n",
    "\n",
    "* <a id='perkins2014'></a>**[Perkins2014]** Jacob Perkins, *Python 3 Text Processing with NLTK 3 Cookbook*, 2014. \n",
    "Capítulo 5 *Part-of-speech Tagging*\n",
    "\n",
    "* <a id='cess2007'></a>**[CESS2007]** Antonia Martí, Mariona Taulé, Lluís Márquez, Manuel Bertran. 2007. \n",
    "CESS-ECE: A Multilingual and Multilevel Annotated Corpus. \n",
    "*see* http://www.lsi.upc.edu/~mbertran/cess-ece/publications\n",
    "\n",
    "* **NLTK** Bird, Steven, Edward Loper and Ewan Klein (2009), Natural \n",
    "Language Processing with Python. O’Reilly Media Inc. *see* http://nltk.org/\n",
    "\n",
    "* (colocar referencias al Pen Treebank POS Tags Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='alphabetic_index'></a>\n",
    "## Índice Alfabético\n",
    "\n",
    "<a id='token'></a>\n",
    "**Token**: señal, indicio, muestra. Se usa generalmente para referirse a la unidad\n",
    "más pequeña de procesamiento: palabras, fonemas, n-grams, etc..\n",
    "\n",
    "\n",
    "Volver al [*Índice*](#indice)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
