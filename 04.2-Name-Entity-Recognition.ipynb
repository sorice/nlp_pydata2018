{
 "metadata": {
  "name": "",
  "signature": "sha256:21de515835c98d2ba24bb827d303996d1b7fae1f6aeb7bcdf9b2e07262728971"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<small><i>This notebook was put together by [Abel Meneses-Abad](http://www.meneses-abad.com) for PyData Vancouver 2018. Source and license info is on [GitHub](https://github.com/sorice/nlp_pydata2018/).</i></small>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='nerc'></a>\n",
      "# Named Entity Recognition (NER)\n",
      "\n",
      "## NER with NLTK\n",
      "\n",
      "NLTK has an excellent MaxEnt backed Named Entity Recognizer that is trained on the Penn Treebank. You can also retrain the chunker if you'd like - the code is very readable to extend it with a Gazette or otherwise.([Bengford2016](#Bengford2016))\n",
      "\n",
      "For this example you need the NLTK *Averaged Perceptron Tagger* (5.9 Mb) and the NLTK *words* corpus (2.4 Mb)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "print(nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(\"John Smith is from the United States of America and works at Microsoft Research Labs\"))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(S\n",
        "  (PERSON John/NNP)\n",
        "  (PERSON Smith/NNP)\n",
        "  is/VBZ\n",
        "  from/IN\n",
        "  the/DT\n",
        "  (GPE United/NNP States/NNPS)\n",
        "  of/IN\n",
        "  (GPE America/NNP)\n",
        "  and/CC\n",
        "  works/VBZ\n",
        "  at/IN\n",
        "  (ORGANIZATION Microsoft/NNP Research/NNP Labs/NNP))\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## NER with Stanford NER Tagger & NLTK\n",
      "\n",
      "You can also wrap the Stanford NER system, which many of you are also probably used to using."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from nltk.tag.stanford import StanfordNERTagger\n",
      "\n",
      "# change the paths below to point to wherever you unzipped the Stanford NER download file\n",
      "stanford_root = '/opt/stanford/stanford-ner-2015-04-20'\n",
      "NER_model = os.path.join(stanford_root, 'classifiers/english.all.3class.distsim.crf.ser.gz')\n",
      "stanford_jar  = os.path.join(stanford_root, 'stanford-ner-3.5.2.jar')\n",
      "\n",
      "st = StanfordNERTagger(NER_model, stanford_jar, 'utf-8')\n",
      "for i in st.tag(\"John Smith is from the United States of America and works at Microsoft Research Labs\".split()):\n",
      "    print('[' + i[1] + '] ' + i[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[PERSON] John\n",
        "[PERSON] Smith\n",
        "[O] is\n",
        "[O] from\n",
        "[O] the\n",
        "[LOCATION] United\n",
        "[LOCATION] States\n",
        "[LOCATION] of\n",
        "[LOCATION] America\n",
        "[O] and\n",
        "[O] works\n",
        "[O] at\n",
        "[ORGANIZATION] Microsoft\n",
        "[ORGANIZATION] Research\n",
        "[ORGANIZATION] Labs\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## NER with FreeLing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='references'></a>\n",
      "##Referencias##\n",
      "\n",
      "* <a id='Bengford2016'></a>\n",
      "**[Bengford2016]** Benjaming Bengford, Tony Ojeda, Laura Lorenz, *Natural Language Processing with NLTK and Gensim*, tutorial at PyCon 2016.\n",
      "Notebook *Intro to NLTK*."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}