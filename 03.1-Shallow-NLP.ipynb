{
 "metadata": {
  "name": "",
  "signature": "sha256:115841c112907998e952686f252e056e17275be8f1e2073139ddde428e3353dc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Bases de NLP#\n",
      "\n",
      "[Ver proceso previo: Pre-Procesamiento de Texto](#text-pre-procesamiento)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Fecha de elaboraci\u00f3n inicial**: 8 de agosto de 2015\n",
      "**\u00daltima actualizaci\u00f3n**: \n",
      "<a id='indice'></a>\n",
      "##\u00cdndice##\n",
      "\n",
      "1. [Datos.](#datos) Descripci\u00f3n de los datos que se utilizar\u00e1n en el notebook.\n",
      "\n",
      "- 1.1 [Transformar los datos.](#transformar_los_datos) de PDF a txt para hacer m\u00e1s f\u00e1cil su\n",
      "manipulaci\u00f3n en python.\n",
      "\n",
      "2. [Ejemplos B\u00e1sicos.](#ejemplos_basicos) Usualmente \u00fatiles para hacer Miner\u00eda de Texto.\n",
      "\n",
      "3. [Operaciones usando elementos estad\u00edsticos.](#operaciones_estadisticas)\n",
      "\n",
      "- 3.1 [Filtrado de Stopwords](#filtrado_de_stopwords)\n",
      "- 3.3 [N-gramas](#n-gramas)\n",
      "- 3.4 [Stemming](#stemming)\n",
      "- 3.5 [Lemmatizacion](#lematizacion)\n",
      "\n",
      "4. [Playfull and Depper Programaci\u00f3n NLP](#playfull_programming)\n",
      "\n",
      "- 4.1 [Ponderaci\u00f3n de T\u00e9rminos](#ponderacion_de_terminos)\n",
      "- 4.2 [Probando Rendimiento](#profiling)\n",
      "\n",
      "[Conclusiones](#conclusiones)\n",
      "\n",
      "[Ejercicios](#ejercicios)\n",
      "\n",
      "[Referencias](#referencias)\n",
      "\n",
      "[\u00cdndice Alfab\u00e9tico](#indice_alfabetico)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='datos'></a>\n",
      "##Datos##\n",
      "\n",
      "Para todos los ejemplos se usar\u00e1n dos libros, uno en ingl\u00e9s y otro en espa\u00f1ol. El \n",
      "primero es **Free Software Free Society** y el segundo una traducci\u00f3n de este primero\n",
      "**Software Libre para una Sociedad Libre**.\n",
      "\n",
      "<a id='transformar_los_datos'></a>\n",
      "###Transformar los datos###\n",
      "Generalmente casi todos los materiales que poseemos son *PDFs* y para operar con textos\n",
      "en python lo mejor es usar .txt o formatos no enriquecidos. \u00bfC\u00f3mo transformar PDF\n",
      "en TXT?\n",
      "\n",
      "Nuestra recomendaci\u00f3n es usar pdftotxt que aparece en los repositorios de GNU/Linux\n",
      "dentro del paquete **poppler-utils**. Si conocen alg\u00fan escript adecuado para esta tarea\n",
      "utilizando la biblioteca *ghostscript* la recomendamos por encima de *pdftotext*. Sin \n",
      "embargo es bastante dif\u00edcil encontrar semejante script, no dudamos de que en el futuro\n",
      "lo encontremos. El comando a ejecutar es sencillo:\n",
      "\n",
      "~$ pdftotext archivo.pdf\n",
      "\n",
      "**Resultado:** archivo.txt\n",
      "\n",
      "Hay que tener en cuenta que este script de *extracci\u00f3n de textos* genera los .txt\n",
      "con muchos problemas: fundamentalmente caracteres extra\u00f1os.\n",
      "Tal vez resultar\u00e1 m\u00e1s \u00fatil para el lector estudiar aplicaciones y bibliotecas m\u00e1s \n",
      "especializadas para este tipo de problema del procesamiento de textos como: Apache-Tika,\n",
      "u otros. Sin embargo en el tema anterior sobre pre-procesamiento, el lector podr\u00e1\n",
      "encontrar como resolver estos problemas sin usar grandes bibliotecas\n",
      "para un buen trabajo con los ejemplos b\u00e1sicos de NLP que se ofrecen a continuaci\u00f3n.\n",
      "\n",
      "<a id='ejemplos_basicos'></a>\n",
      "##Ejemplos b\u00e1sicos al estilo del libro de NLTK##\n",
      "\n",
      "Una de las primeras cosas interesantes de un texto, es saber cuantas palabras contiene \n",
      "un texto."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SoftwareWars.txt is generated with pdftotext from SoftwareWars.pdf\n",
      "texto = open('data/SoftwareWars.txt').read()\n",
      "words = 0\n",
      "for line in texto.split('\\n'):\n",
      "    for word in line.split():\n",
      "        words +=1\n",
      "print (\"Total de palabras: \", words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total de palabras:  95976\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SoftwareWars2.txt is a normalized version of SoftwareWars.txt\n",
      "texto = open('data/SoftwareWars2.txt').read().lower()\n",
      "words = 0\n",
      "for line in texto.split('\\n'):\n",
      "    for word in line.split():\n",
      "        words +=1\n",
      "print (\"Total de palabras: \", words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total de palabras:  102721\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Un peque\u00f1o ejemplo para contar oraciones. test2.txt es una tesis ([Avello2016](#Avello2016)) normalizada con el notebook anterior."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tesis = open('data/Avello2016n.txt').read()\n",
      "for line in tesis.split('\\n'):\n",
      "    for i,sentence in enumerate(line.split('.')):\n",
      "        count = i\n",
      "print (count)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2032\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ejemplo con **NLTK**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tokenize import RegexpTokenizer\n",
      "tokenizer = RegexpTokenizer(\"\\s+\", gaps=True)\n",
      "tokens = tokenizer.tokenize(texto)\n",
      "print (\"Total de palabras: \", len(tokens))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total de palabras:  102721\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En ambos casos se devuelve el total de palabras(o tokens) divididos por el caracter\n",
      "*espacio*. Sin embargo las palabras en un texto se repiten. \u00bfC\u00f3mo saber las palabras\n",
      "\u00fanicas?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens_unique=set([])\n",
      "tokens_unique = set(tokens)\n",
      "print (\"Palabras \u00fanicas:\", len(tokens_unique))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Palabras \u00fanicas: 3082\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como se puede ver en el libro Bird et al.[[1](#Bird2009)] la pregunta m\u00e1s simple y \n",
      "com\u00fan que se hace uno al ver estas cifras suelen ser: \u00bfCu\u00e1l es el promedio de palabras\n",
      "por p\u00e1gina? \u00bfCu\u00e1l es la palabra m\u00e1s utilizada? \u00bfQu\u00e9 palabras se usan una vez? Veamos\n",
      "algunas formas de calcularlo, para ello necesitaremos algunas funciones extras:\n",
      "\n",
      "<a id='sect2.5'></a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#Inicializar un diccionario para guardar el # de apariciones de cada palabra.\n",
      "dict = {}\n",
      "for word in tokens_unique:\n",
      "    dict[word]=0\n",
      "#Diccionario con word = # apariciones.\n",
      "for token in tokens:\n",
      "    dict[token]+=1\n",
      "#Operar con una tupla puede ser mejor. Lista([#apariciones,word])\n",
      "tupla = []\n",
      "for word in dict:\n",
      "    tupla.append([dict[word],word])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Ver 5 palabras aleatoriamente contenidas en el diccionario.\n",
      "import random\n",
      "for i in random.sample(range(len(dict)),5):\n",
      "    print (tupla[i][1],\":\",tupla[i][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "HU_07 : 1\n",
        "cinco : 1\n",
        "casos : 1\n",
        "conforman : 1\n",
        "Carly : 1\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Esta tupla puede ser ordenada de la siguiente forma: al poner el # de apariciones \n",
      "delante, podemos usar el elemento *tupla[i][0]* como par\u00e1metro de ordenamiento."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tupla=sorted(tupla)\n",
      "print (\"Las 5 palabras m\u00e1s utilizadas son:\")\n",
      "for i in range(1,6):\n",
      "    print (tupla[-i][1],\":\",tupla[-i][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Las 5 palabras m\u00e1s utilizadas son:\n",
        ". : 2032\n",
        "de : 1091\n",
        "la : 578\n",
        "en : 348\n",
        "el : 275\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"5 palabras que se usan una vez:\")\n",
      "for i in range(5):\n",
      "    print (tupla[i][1],\":\",tupla[i][0])\n",
      "#N\u00famero de p\u00e1ginas del libro After the Software War = 300\n",
      "print (\"Promedio de palabras por p\u00e1gina\", len(tokens)/300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5 palabras que se usan una vez:\n",
        "#m : 1\n",
        "#p : 1\n",
        "00002942 : 1\n",
        "00003133 : 1\n",
        "00078760 : 1\n",
        "Promedio de alabras por p\u00e1gina 56.733333333333334\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (dict[\"software\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "19\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='operaciones_estadisticas'></a>\n",
      "#Operaciones usando elementos estad\u00edsticos#\n",
      "\n",
      "<a id='filtrado_de_stopwords'></a>\n",
      "##Filtrado de Stopwords##\n",
      "\n",
      "Como habremos podido observar en la respuesta a *\"las palabras m\u00e1s usadas\"*, la mayor\u00eda\n",
      "de ellas son palabras que no contienen significado o no son ni verbos, ni sustantivos, \n",
      "ni adjetivos. En NLP se acostumbra a eliminar estas palabras para procesar el resto m\u00e1s\n",
      "significativo. Para hacerlo necesitamos normalmente un fichero de texto con los \n",
      "stopwords que por lo general y por convenci\u00f3n se han definido o calculado. \n",
      "En nuestro caso usaremos los de NLTK.Una versi\u00f3n personalizada por el autor tambi\u00e9n\n",
      "se usa, hecha a partir de los originales de *NLTK* y \n",
      "[Snowball](http://snowball.tartarus.org/texts/introduction.html)\n",
      "\n",
      "**Nota**: otro elemento contenido en el siguiente algoritmo es la eliminaci\u00f3n de las \n",
      "palabras con longitud = 1, todas palabras sin significado."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import time\n",
      "from nltk.corpus import stopwords\n",
      "timei = time.time()\n",
      "english_stops = set(stopwords.words('en'))\n",
      "tokens_afterstops=[]\n",
      "for k in range(len(tokens)-1):\n",
      "    if tokens[k] not in english_stops and len(tokens[k])>1:\n",
      "        tokens_afterstops.append(tokens[k])\n",
      "timef = time.time()-timei\n",
      "print (\"Tiempo de filtrado de stopwords: \",timef)\n",
      "\n",
      "tokens_unique1 = set(tokens_afterstops)\n",
      "dict1 = {} #dict con keys = set de tokens after stops\n",
      "for word in tokens_unique1:\n",
      "    dict1[word]=0\n",
      "\n",
      "tupla1 = [] #Creando lista de tuplas(# ocurrencias,word) sin stopwords\n",
      "for token in tokens_afterstops:\n",
      "    dict1[token]+=1\n",
      "for word in dict1:\n",
      "    tupla1.append([dict1[word],word])\n",
      "tupla1=sorted(tupla1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tiempo de filtrado de stopwords:  0.017447471618652344\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"Palabras \u00fanicas sin stops:\", len(tokens_unique1))\n",
      "print (\"Las 5 palabras m\u00e1s utilizadas despu\u00e9s de filtrar los stopwords son:\")\n",
      "for i in range(1,6):\n",
      "    print (tupla1[-i][1],\":\",tupla1[-i][0])\n",
      "print (\"Total de palabras del texto: \", len(tokens))\n",
      "print (\"Palabras en el texto sin stopwords:\", len(tokens_afterstops))\n",
      "print (\"Palabras eliminadas en el proceso de filtrado de stopwords:\", \n",
      "len(tokens)-len(tokens_afterstops))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Palabras \u00fanicas sin stops: 3002\n",
        "Las 5 palabras m\u00e1s utilizadas despu\u00e9s de filtrar los stopwords son:\n",
        "de : 1091\n",
        "la : 578\n",
        "en : 348\n",
        "el : 275\n",
        "se : 213\n",
        "Total de palabras del texto:  17020\n",
        "Palabras en el texto sin stopwords: 13912\n",
        "Palabras eliminadas en el proceso de filtrado de stopwords: 3108\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='n-gramas'></a>\n",
      "##N-gramas##\n",
      "\n",
      "La t\u00e9cnica de n-gramas es muy simple, consiste en dividir el texto tanto en caracteres\n",
      "como en palabras y hacer nuevos tokens compuestos por n-caracteres o n-palabras. En \n",
      "este ejemplo veremos una divisi\u00f3n en *n-palabras*. Basadas en las propiedades de **Los\n",
      "Modelos ocultos de Markov** esta nueva lista, para $n \\geqq 3$ suele ser mucho m\u00e1s \u00fatil \n",
      "que las palabras simples. La func **ngrams2** fue el segundo dise\u00f1o elaborado en abril\n",
      "de 2015 para el algoritmo de detecci\u00f3n de texto reusado (del autor) en su primera \n",
      "versi\u00f3n. La versi\u00f3n inicial del 2013 se incluye en la secci\u00f3n de performance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ngrams2(text,n):\n",
      "    tokens=[];ngram=\"\";ngram_list=[]\n",
      "    for word in text.split():\n",
      "        tokens.append(word)\n",
      "    if n >= len(tokens):\n",
      "        raise Exception(\"Not possible, n most be shorter than total words.\")\n",
      "    for i in range(len(tokens)-n+1):\n",
      "        for j in range(i,i+n):\n",
      "            ngram+=tokens[j]+\" \"\n",
      "        ngram_list.append(ngram)\n",
      "        ngram=\"\"\n",
      "    return ngram_list\n",
      "\n",
      "texto = open('data/SoftwareWars2.txt').read()\n",
      "ngramsl=ngrams2(texto,3)\n",
      "print (\"Total de n-gramas: %d.\" % len(ngramsl))\n",
      "ngramsl_unique = set(ngramsl)\n",
      "print (\"N-gramas \u00fanicos: %d.\" % len(ngramsl_unique))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total de n-gramas: 102719.\n",
        "N-gramas \u00fanicos: 89823.\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A continuaci\u00f3n incluyo una actualizaci\u00f3n de este algoritmo con conocimientos aprendidos\n",
      "en marzo del 2016 al estudiar high performance in python [[3](#Gorelick2014)]. Implementando c\u00f3digos \n",
      "pythonicos utilizando estructuras optimizadas (deque) y la funci\u00f3n join de la clase str."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import deque\n",
      "\n",
      "def ngrams4(text,n):\n",
      "    tokens=[];ngram_list=deque()\n",
      "    for word in text.split():\n",
      "        tokens.append(word)\n",
      "    if n >= len(tokens):\n",
      "        raise Exception(\"Not possible, n most be shorter than total words.\")\n",
      "    for i in range(len(tokens)-n+1):\n",
      "        ngram_tokens = [tokens[j] for j in range(i,i+n)]\n",
      "        ngram =\" \".join(ngram_tokens)\n",
      "        ngram_list.append(ngram)\n",
      "    return ngram_list\n",
      "\n",
      "texto = open('data/SoftwareWars2.txt').read()\n",
      "ngramsl=ngrams4(texto,3)\n",
      "print (\"Total de n-gramas: %d.\" % len(ngramsl))\n",
      "ngramsl_unique = set(ngramsl)\n",
      "print (\"N-gramas \u00fanicos: %d.\" % len(ngramsl_unique))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total de n-gramas: 102719.\n",
        "N-gramas \u00fanicos: 89823.\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (ngramsl[26])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "digital download .\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Funci\u00f3n ngrams basada en iteradores, el retorno **yield** y las funci\u00f3n interna de las listas __iadd__. Elaborado el \n",
      "3 de septiembre de 2016.\n",
      "Como se ver\u00e1 en la secci\u00f3n de [*Profiling*](#profiling) esta implementaci\u00f3n es la m\u00e1s r\u00e1pida de todas(10x) respecto a la\n",
      "original del 2013.\n",
      "La idea de esta funci\u00f3n sali\u00f3 de revisar la implementaci\u00f3n del m\u00e9todo *_split* de la clase **NGram** del m\u00f3dulo \n",
      "[ngram](http://github.com/gpoulter/python-ngram) de Graham Poulter, el mismo es inclu\u00eddo dentro de los recursos \n",
      "de este tema para una revisi\u00f3n m\u00e1s detallada por parte de los estudiantes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = \"esto es solo una prueba m\u00e1s\"\n",
      "def ngram_split(text,n):\n",
      "    ngram = ''\n",
      "    gram_count = 0\n",
      "    for i,word in enumerate(text.split(),1):\n",
      "        if gram_count-n == -1 and i > n:\n",
      "            ngram = ngram[ngram.find(' ')+1:]\n",
      "        ngram += word+' '; gram_count+=1\n",
      "        if gram_count == n:\n",
      "            gram_count -= 1\n",
      "            yield ngram\n",
      "        \n",
      "def ngrams5(text,n):\n",
      "    ngrams = []\n",
      "    ngrams.__iadd__(ngram_split(text,n))\n",
      "    if len(ngrams) > 0:\n",
      "        return ngrams\n",
      "    else:\n",
      "        raise Exception(\"Not possible, n is longer than total words.\")\n",
      "\n",
      "ngrams = ngrams5(text,3)\n",
      "print(ngrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['esto es solo ', 'es solo una ', 'solo una prueba ', 'una prueba m\u00e1s ']\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En la secci\u00f3n [*Profiling*](#profiling) se analiza el performance de estas \n",
      "implementaciones, y el de otras bibliotecas fundamentales de python para NLP. Al \n",
      "concluir se incluye una secci\u00f3n [NLTK ngrams](#nltk_ngrams) para evaluar la dificultad\n",
      "de usar esta funci\u00f3n en NLTK."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='stemming'></a>\n",
      "##Stemming##\n",
      "\n",
      "Proceso mediante el cual se eliminan de la palabra los \u201cmorfemas\u201d, utilizando reglas \n",
      "predefinidas que se corresponden con las terminaciones m\u00e1s comunes de las palabras en \n",
      "un idioma. Trabaja la morfolog\u00eda de las palabras."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem import PorterStemmer\n",
      "stemmer = PorterStemmer()\n",
      "words_stops = len(tokens) #Longitud de tokens despu\u00e9s de los dos primeros pasos.\n",
      "tokens_stem=[]\n",
      "for i in range(len(tokens_afterstops)):\n",
      "    tokens_stem.append(stemmer.stem(tokens_afterstops[i]))\n",
      "        #print i\n",
      "\n",
      "timei = time.time()\n",
      "stemmer = PorterStemmer()\n",
      "words_stops = len(tokens) #Longitud de tokens despu\u00e9s de los dos primeros pasos.\n",
      "tokens_stem=[]\n",
      "for i in range(len(tokens)):\n",
      "    tokens_stem.append(stemmer.stem(tokens[i]))\n",
      "        #print i\n",
      "timef = time.time()-timei\n",
      "print (\"Tiempo de steeming: \",timef)\n",
      "\n",
      "print (tokens_afterstops[27],\":\",tokens_stem[27])\n",
      "tokens_unique2 = set(tokens_stem)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tiempo de steeming:  0.09572577476501465\n",
        "Ing : Alexand\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"Palabras reducidas durante el steaming: de %d se redujeron en %d.\" \n",
      "       % (len(tokens_unique1), len(tokens_unique1)-len(tokens_unique2)))\n",
      "print (\"Palabras \u00fanicas tras el steamming: %d.\" % (len(tokens_unique2)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Palabras reducidas durante el steaming: de 3002 se redujeron en 184.\n",
        "Palabras \u00fanicas tras el steamming: 2818.\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='lematizacion'></a>\n",
      "##Lematizaci\u00f3n##\n",
      "\n",
      "Proceso mediante el cual se extrae el \u201clexema\u201d de la palabra. Generalmente es necesario\n",
      "utilizar una base de datos (BD) que contenga informaci\u00f3n de los lexemas o lemas (como \n",
      "tambi\u00e9n se le suele llamar a los lexemas), estas BD son generalmente sem\u00e1nticas. \n",
      "Trabaja la morfolog\u00eda de las palabras.\n",
      "\n",
      "En el siguiente ejemplo se utiliza Wordnet y su implementaci\u00f3n en NLTK. **Wordnet** es \n",
      "una de las BD sem\u00e1nticas m\u00e1s importantes creadas por la humanidad cuyas versiones en \n",
      "ingl\u00e9s son licenciadas bajo principios libres. Se puede encontrar varias versiones de ella\n",
      "en los diferentes repositorios de linux. Una versi\u00f3n profesional de Wordnet en espa\u00f1ol\n",
      "existe pero es comercial y su costo es de m\u00e1s de 5000 euros."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from nltk.stem import WordNetLemmatizer\n",
      "lemmatizer = WordNetLemmatizer()\n",
      "\n",
      "#Lematizando.\n",
      "dict_lem = {}\n",
      "timei=time.time()\n",
      "for i in range(len(tokens)):\n",
      "    dict_lem[tokens[i]] = lemmatizer.lemmatize(tokens[i])\n",
      "timef=time.time()-timei\n",
      "print(\"Tiempo de lematizaci\u00f3n:\", timef)\n",
      "\n",
      "#Construyendo un diccionario con los t\u00e9rminos \u00fanicos dict_lem after stops\n",
      "#y una lista con estos mismos t\u00e9rminos.\n",
      "\n",
      "dict_lem = {}\n",
      "for token in tokens_unique1:\n",
      "    dict_lem[token] = token\n",
      "tokens_uniqueB = list(dict_lem.keys()) #ojo: en py3 el m\u00e9todo keys() devuelve un objeto de tipo dict_keys (no-list) y no indexable.\n",
      "\n",
      "#Lematizando los t\u00e9rminos \u00fanicos.\n",
      "for i in range(len(tokens_uniqueB)):\n",
      "    dict_lem[tokens_uniqueB[i]] = lemmatizer.lemmatize(tokens_uniqueB[i])\n",
      "\n",
      "tokens_lem = tokens_afterstops.copy()\n",
      "for i in range(len(tokens_afterstops)):\n",
      "    tokens_lem[i] = dict_lem[tokens_afterstops[i]]\n",
      "        \n",
      "tokens_unique3 = set(tokens_lem)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tiempo de lematizaci\u00f3n: 2.6319186687469482\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "setDiff = tokens_unique1.union(tokens_unique3) - tokens_unique1.intersection(tokens_unique3)\n",
      "\n",
      "count = 10\n",
      "for i in range(len(tokens_lem)):\n",
      "    if tokens_lem[i] != tokens_afterstops[i]:\n",
      "        print (tokens_afterstops[i],\":\",tokens_lem[i])\n",
      "        count-=1\n",
      "        if count < 1:\n",
      "            break\n",
      "print (\"Palabras reducidas durante la Lematizaci\u00f3n de %d se redujeron en %d\" \n",
      "       % (len(tokens_unique1), len(tokens_unique1)-len(tokens_unique3)))\n",
      "print (\"Palabras \u00fanicas tras el steamming:\", len(tokens_unique3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mes : me\n",
        "las : la\n",
        "fines : fine\n",
        "genera : genus\n",
        "las : la\n",
        "morales : morale\n",
        "es : e\n",
        "todas : toda\n",
        "las : la\n",
        "personas : persona\n",
        "Palabras reducidas durante la Lematizaci\u00f3n de 3002 se redujeron en 17\n",
        "Palabras \u00fanicas tras el steamming: 2985\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Es importante destacar que tras el stemming quedaron 2818 palabras y tras la \n",
      "lematizaci\u00f3n quedaron 2985, en ambos casos se parte del resultado del filtrado\n",
      "de stopwords. En ambos casos tambi\u00e9n estamos en presencia de una **reducci\u00f3n de la\n",
      "dimensionalidad**, o sea disminuir el tama\u00f1o de los datos a analizar perdiendo la menor\n",
      "cantidad de informaci\u00f3n.\n",
      "Sin embargo el autor recomienda utilizar las 2985 palabras de la lematizaci\u00f3n porque es\n",
      "un proceso donde se puede regresar a la palabra original, el stemming hace un \n",
      "tronchado de las palabras que es irreversible. S\u00ed hay que notar que la lematizaci\u00f3n es\n",
      "m\u00e1s lenta, pero tiene en cuenta para generar cada lema la funci\u00f3n POS de cada palabra\n",
      "*(o sea s\u00ed esta es un verbo, sustantivo, adjetivo o adverbio, una misma palabra puede\n",
      "tener lemas diferentes en funci\u00f3n de su POS)*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='playfull_programming'></a>\n",
      "#Playfull and Depper Programming#\n",
      "\n",
      "Esta secci\u00f3n es una secci\u00f3n avanzada sobre NLP y sus procesos b\u00e1sicos. \n",
      "En las secciones anteriores hemos filtrado \n",
      "los stopwords que son palabras sin contenido sem\u00e1ntico y las m\u00e1s frecuentes, en el \n",
      "caso del steamming se elimina algunos sufijos y se puede hacer con expresiones regulares\n",
      "o basados en reglas. En cualquiera de estos casos la estad\u00edstica es fundamental para \n",
      "el algoritmo o para el mecanismo de aprendizaje a utilizar. Y en todos los pasos vimos\n",
      "como se reduce el n\u00famero de palabras tratando de encontrar las m\u00e1s importantes.\n",
      "\n",
      "Veamos ahora un ejemplo de NLP un \u00e1rea de la computaci\u00f3n muy relacionada, **Information \n",
      "Retrieval** (*o Recuperaci\u00f3n de Informaci\u00f3n*). Se trata de la *Ley de Luhn*[[2](#Luhn1958)], o el \n",
      "hallazgo de la banda de las palabras m\u00e1s importantes de un documento.\n",
      "\n",
      "<a id='ponderacion_de_terminos'></a>\n",
      "##Ponderaci\u00f3n de T\u00e9rminos##\n",
      "**Ley de Luhn**\n",
      "\n",
      "Luhn plante\u00f3 que los textos se comportan como una funci\u00f3n logar\u00edtmica negativa o una\n",
      "funci\u00f3n de cola larga. Donde los stopwords est\u00e1n al inicio, y las palabras poco \n",
      "frecuentes que tampoco definen el contexto est\u00e1n al final. Veamos una gr\u00e1fica de este\n",
      "libro. Usando la variable *tupla* de la secci\u00f3n de c\u00f3digo [2.5](#sect2.5) construimos\n",
      "un arreglo de *numpy* del cual se extrae la media($\\mu$) y la varianza($\\sigma$), \n",
      "valores que posteriormente se usar\u00e1n en muchos c\u00e1lculos."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['text', 'random']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "xarray = []\n",
      "t=scipy.linspace(0,len(tupla),num=len(tupla))\n",
      "for i in range(len(tupla)):\n",
      "    xarray.append(tupla[i][0])\n",
      "xarray.reverse()\n",
      "\n",
      "x = numpy.array(xarray,dtype=numpy.int16)\n",
      "mux = x.mean()\n",
      "sigmax = x.std()\n",
      "print (mux) \n",
      "print (sigmax)\n",
      "print (x.shape)\n",
      "\n",
      "plt.plot(t[:1000],x[:1000])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.5223880597\n",
        "45.05733947\n",
        "(3082,)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f76e4d13860>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Ejemplo Experimental de Luhn**\n",
      "\n",
      "###1er paso: Generar distribuci\u00f3n zeta de prueba.###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist = np.random.zipf(2,size=1000)              # generar distribuci\u00f3n zeta\n",
      "dist = np.fix(dist)                             # dist zeta aproximada\n",
      "dist1=np.sqrt(dist**2)                          # del negative values\n",
      "dist2 = np.array(dist1,dtype=np.int16)          # llevado a enteros\n",
      "dist3 = np.sort(dist2,axis=None,kind='mergesort') # ordenados de menor a mayor\n",
      "mu = dist2.mean()\n",
      "sigma = dist2.std()\n",
      "dist3[:]=dist3[::-1]                            # ordenado de mayor a menor\n",
      "plot(t[:200],dist3[:200])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f76e1f65160>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f76e286c1d0>"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###2do paso: Comprobar que el documento cumple con la ley de Zipf.###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Si cumple con la ley de zipf la representaci\u00f3n sigte ser\u00e1 aprox una recta.\n",
      "t = arange(1,1001,1)\n",
      "logf = log(dist3)\n",
      "logt = log(t)\n",
      "plot(logf,logt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f76e498e550>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEACAYAAACatzzfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f76e49c4eb8>"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###3er paso: Generar una distribuci\u00f3n normal a partir de Zeta.###\n",
      "\n",
      "Este paso es una propuesta personal a partir de la oscuridad en el art\u00edculo de Luhn \n",
      "[[2](#Luhn1958)] con respecto a los bordes de corte. Algunos art\u00edculos consideran\n",
      "que en la determinaci\u00f3n de estos l\u00edmites hay cierto empirismo. Los c\u00e1lculos se hacen\n",
      "utilizando una hip\u00f3tesis nula \n",
      "[Keith web book, chapter2](http://www.dcs.gla.ac.uk/Keith/Chapter.2/Ch.2.html)/\n",
      "[inlink](./htmls/3.1/Keith_Ch2/index.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "bins = np.arange(0,1000,1)\n",
      "dist4 = dist3/float(1000)\n",
      "#Ploting Zipf distribution\n",
      "plt.plot(t[10:200],dist4[10:200])\n",
      "sigma = dist3.std()\n",
      "mu = dist3.mean()+3*sigma\n",
      "pdf = (1/(sigma * numpy.sqrt(2 * numpy.pi))\n",
      "* numpy.exp( - (bins - mu)**2 / (2 * sigma**2) ))\n",
      "\n",
      "#Ploting density function\n",
      "plt.plot(bins[10:200],pdf[10:200])\n",
      "\n",
      "perc_05 = int(mu-2*sigma)\n",
      "perc_95 = int(mu+2*sigma)\n",
      "print(perc_05, perc_95)\n",
      "# Dibujando la l\u00ednea discont\u00ednua del lower cut-off.\n",
      "plt.axvline(perc_05,label='05 perc',c='r')\n",
      "# Dibujando la l\u00ednea discont\u00ednua del upper cut-off.\n",
      "plt.axvline(perc_95,label='95t perc',c='m')\n",
      "plt.show()\n",
      "print (mu, sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24 102\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f76e26bfc50>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "63.5438021153 19.6629340384\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Siguiendo estos 3 pasos en nuestro libro real los valores son la palabra 24 y la 102 la \n",
      "que limitan el intervalo de las palabras m\u00e1s significativas de este texto."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (tupla1[-perc_05][1],\":\",tupla1[-perc_05][0])\n",
      "print (tupla1[-perc_95][1],\":\",tupla1[-perc_95][0])\n",
      "print ('All important words:', tupla1[len(tupla1)-perc_95:len(tupla1)-perc_05+1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "texto : 60\n",
        "Python : 17\n",
        "All important words: [[17, 'Python'], [17, 'formato'], [17, 'lenguaje'], [17, 'noun'], [17, 'puede'], [17, 'ser'], [17, 'tener'], [17, 'trabajo'], [18, 'Las'], [18, 'excepciones'], [18, 'herramientas'], [18, 'insertar'], [18, 'kid'], [19, 'Editar'], [19, 'University'], [19, 'bot\u00f3n'], [19, 'buscar'], [19, 'edici\u00f3n'], [19, 'excepci\u00f3n'], [19, 'software'], [19, 'tecnolog\u00edas'], [20, 'QtNLP'], [20, 'espa\u00f1ol'], [20, 'ingl\u00e9s'], [21, 'Princeton'], [22, 'Atributos'], [22, 'al_'], [22, 'entidad'], [23, 'Available'], [23, 'Buscar'], [23, 'LA'], [23, 'Qt'], [23, 'et'], [23, 'prueba'], [24, 'DEL'], [24, 'Figura'], [24, 'forma'], [25, 'ARQUITECTURA'], [25, 'producto'], [26, 'Mostrar'], [26, 'entre'], [26, 'esta'], [26, 'sistema'], [27, 'Historia'], [27, 'uso'], [28, 'En'], [28, 'Es'], [28, 'al'], [28, 'debe'], [28, 'lo'], [29, 'La'], [29, 'Los'], [29, 'm\u00f3dulo'], [29, 'relaci\u00f3n'], [29, 'usuario'], [30, 'este'], [30, 'proyecto'], [31, 'El'], [31, 'l\u00e9xica'], [32, 'Caso'], [32, 'tabla'], [33, '2016'], [33, 'Prueba'], [33, 'SOFTWARE'], [34, 'QtNLP_Wordnet'], [34, 'Usuario'], [35, 'son'], [37, 'su'], [38, 'Nombre'], [41, 'aplicaci\u00f3n'], [48, 'atributos'], [50, 'Descripci\u00f3n'], [50, 'como'], [51, 'desarrollo'], [55, 'relaciones'], [58, 'No'], [59, 'CAP\u00cdTULO'], [59, 'por'], [60, 'texto']]\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Este m\u00e9todo es ampliamente utilizado en la generaci\u00f3n de res\u00famenes autom\u00e1ticos. Puede\n",
      "servir para dar un peso a las palabras dentro del documento, y extraer las estructuras\n",
      "m\u00e1s ponderadas: oraciones, p\u00e1rrafos, etc. Como es posible observar en el \n",
      "ejemplo del libro \"After de Software Wars\", este m\u00e9todo deja de 10127 palabras solo \n",
      "unas 200 significativas."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='profiling'></a>\n",
      "##Profiling##\n",
      "\n",
      "Vamos a comparar este m\u00e9todo de Abel de n-grams del 2015, el ngram_index del 2013\n",
      "y el m\u00e9todo *ngrams* de la biblioteca belga **Patterns**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import clock\n",
      "\n",
      "from script.tokens import ngram_index as ngrams1\n",
      "start_time2 = clock()\n",
      "ngramsa = ngrams1(texto,3)\n",
      "end_time2 = clock()-start_time2\n",
      "\n",
      "start_time1 = clock()\n",
      "ngramsb = ngrams2(texto,3)\n",
      "end_time1 = clock()-start_time1\n",
      "\n",
      "\"\"\"Esta secci\u00f3n solo se puede usar en py2, pues la \n",
      "biblioteca Pattern no tiene soporte para py3.\"\"\"\n",
      "#from pattern.en import ngrams as ngrams3\n",
      "#start_time3 = clock()\n",
      "#ngramsc = ngrams3(texto,n=3)\n",
      "#end_time3 = clock()-start_time3\n",
      "\n",
      "start_time4 = clock()\n",
      "ngramsd = ngrams4(texto,3)\n",
      "end_time4 = clock()-start_time4\n",
      "\n",
      "start_time5 = clock()\n",
      "ngramse = ngrams5(texto,3)\n",
      "end_time5 = clock()-start_time5\n",
      "\n",
      "print ('Funci\u00f3n de ngrams nov/2013: %.4f' % end_time2)\n",
      "%timeit ngrams1(texto,3)\n",
      "print (len(ngramsb))\n",
      "\n",
      "print ('Funci\u00f3n de ngrams abril/2015: %.4f' % end_time1)\n",
      "%timeit ngrams2(texto,3)\n",
      "print (len(ngramsa))\n",
      "\n",
      "#print ('Funci\u00f3n de ngrams Pattern octubre/2013: %.4f' % end_time3)\n",
      "#%timeit ngram3(texto,3)\n",
      "#print (len(ngramsc))\n",
      "\n",
      "print ('Funci\u00f3n de ngrams marzo/2016: %.4f' % end_time4)\n",
      "%timeit ngrams4(texto,3)\n",
      "print (len(ngramsd))\n",
      "\n",
      "print ('Funci\u00f3n de ngrams septiembre/2016: %.4f' % end_time5)\n",
      "%timeit ngrams5(texto,3)\n",
      "print (len(ngramse))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Funci\u00f3n de ngrams nov/2013: 0.8346\n",
        "1 loops, best of 3: 779 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102719\n",
        "Funci\u00f3n de ngrams abril/2015: 0.1236\n",
        "10 loops, best of 3: 123 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102719\n",
        "Funci\u00f3n de ngrams marzo/2016: 0.1711\n",
        "10 loops, best of 3: 150 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102719\n",
        "Funci\u00f3n de ngrams septiembre/2016: 0.1011\n",
        "10 loops, best of 3: 89.2 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102719\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textt = open('tokens.py').read()\n",
      "textt[1159:1165]\n",
      "\n",
      "print (ngramsa[26])\n",
      "print (ngramsb[26])\n",
      "print (ngramsd[26])\n",
      "print (ngramse[26])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " digital download .\n",
        "digital download . \n",
        "digital download .\n",
        "digital download . \n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='nltk_ngrams'></a>\n",
      "##NLTK Ngrams##\n",
      "\n",
      "**Nota:** NLTK tiene una funci\u00f3n de ngramas\n",
      "     \n",
      "    from nltk import ngrams\n",
      "\n",
      "Sin embargo en la versi\u00f3n 3 esta funci\u00f3n es un generador, y como entrada hay que pasar\n",
      "una secuencia y no el texto original. Ejemplo para obtener un resultado similar al que\n",
      "hemos obtenido con las 4 funciones anteriores hacemos lo siguiente:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import ngrams as ngramsNLTK\n",
      "from nltk.tokenize import word_tokenize\n",
      "texto = open('SoftwareWars2.txt').read().lower()\n",
      "\n",
      "def ngrams6(texto,number):\n",
      "    ngramse =[]\n",
      "    token_text = word_tokenize(texto)\n",
      "    ingramse = ngramsNLTK(token_text,number)\n",
      "    for i in ingramse:\n",
      "        ngramse.append(i)\n",
      "    return ngramse\n",
      "\n",
      "start_time5 = clock()\n",
      "ngramse = ngrams6(texto,3)\n",
      "end_time5 = clock()-start_time5\n",
      "print ('Funci\u00f3n de ngrams NLTK octubre/2015: %.4f' % end_time5)\n",
      "%timeit ngrams6(texto,3)\n",
      "print (len(ngramsd))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Funci\u00f3n de ngrams NLTK octubre/2015: 1.0388\n",
        "1 loops, best of 3: 1 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102719\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como puede observarse aqu\u00ed el resultado es m\u00e1s lento que en cualquiera de los anteriores\n",
      "fundamentalmente por el uso de dos funciones (tokenizar y luego ngramas). En general\n",
      "es 0.1x (10 veces m\u00e1s lenta) que la mejor soluci\u00f3n local.\n",
      "\n",
      "Para la funci\u00f3n de ngrams tambi\u00e9n fueron analizados "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='conclusiones'></a>\n",
      "\n",
      "##Conclusiones##\n",
      "- El procesamiento de textos es un mundo fascinante y de enormes utilidades.\n",
      "- En python la biblioteca **NLTK** es un software maduro, aunque con algunas\n",
      "insuficiencias para el idioma espa\u00f1ol.\n",
      "- Las t\u00e9cnicas fundamentales para descomponer un texto se basan en estad\u00edstica.\n",
      "- Wordnet y otros recursos como Babelfish suelen dar excelentes resultados para \n",
      "procesamiento de la lengua basado en conocimiento. Sin embargo estos m\u00e9todos pueden\n",
      "consumir grandes cuotas de HD, CPU y Memoria RAM.\n",
      "- Combinado con leyes de la ling\u00fc\u00edstica como la Ley de Luhn estas t\u00e9cnicas sirven de\n",
      "base para operaciones m\u00e1s complejas dentro de otras \u00e1reas de NLP, Miner\u00eda de Texto e \n",
      "Information Retrieval.\n",
      "- En ocasiones es importante tener presente que para funciones muy utilizadas y simples,\n",
      "podr\u00eda ser m\u00e1s \u00fatil implementar nuestra propia funci\u00f3n. Es el ejemplo explicado en la\n",
      "secci\u00f3n de rendimiento y NTLK ngrams."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='ejercicios'></a>\n",
      "\n",
      "##Ejercicios##\n",
      "\n",
      "* **Ejercicio 1:** Implemente un algoritmo que dado un texto cuente las oraciones que hay en \u00e9l.\n",
      "Pruebe este algoritmo con el texto pre-procesado y sin procesar.\n",
      "* **Ejercicio 2:** Implemente una tokenizaci\u00f3n de textos en ingl\u00e9s que transforme las contracciones.\n",
      "Cuente el n\u00famero de palabras \u00fanicas con esta implementaci\u00f3n y compare con la estudiada\n",
      "en clase.\n",
      "* **Ejercicio 3:** Re-implemente la tokenizaci\u00f3n estudiada en clases, pero donde el algoritmo sea capaz\n",
      "de entender que *The* y *the* son la misma palabra.\n",
      "* **Ejercicio 4:** Proponga un nuevo conjunto de stopwords, dise\u00f1e una ecuaci\u00f3n para calcularlos\n",
      "autom\u00e1ticamente.\n",
      "* **Ejercicio 5:** Encuentre en internet palabras con ra\u00edces lingu\u00edsticas o lemas poco comunes. Pruebe\n",
      "los resultados con el steeming de NLTK. Redise\u00f1e el algoritmo de Poter para que reduzca\n",
      "bien las palabras encontradas por usted.\n",
      "* **Ejercicio 6:** Proponga una lematizaci\u00f3n utilizando diccionarios de palabras existentes en internet.\n",
      "* **Ejercicio 7:** Lea el cap\u00edtulo de m\u00e1quinas de estado de Jurafsky, e implemente una m\u00e1quina parecida\n",
      "en python.\n",
      "* **Ejercicio 8:** Utilice los diccionarios de libreoffice de afijos, infijos, etc e implemente un \n",
      "lematizador que utilice este recurso."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Volver al [*\u00cdndice*](#indice).\n",
      "\n",
      "<a id='referencias'></a>\n",
      "##Referencias##\n",
      "\n",
      "<a id='Bird2009'></a>\n",
      "[1] *[Bird2009]* Steven Bird, Ewan Klain & Edward Loper,. \n",
      "Book **Natural Language Processing with Python**. 2009. \n",
      "p. 10 **ISBN**: 978-0-596-51649-9\n",
      "\n",
      "<a id='Luhn1958'></a>\n",
      "[2] *[Luhn1958]* H.P. Luhn. Paper **The Automatic Creation of Literature Abstract**. \n",
      "*IBM Journal*, 1958.\n",
      "\n",
      "<a id='Gorelick2014'></a>\n",
      "[3] *[Gorelick2014]* Micha Gorelick & Ian Ozsvald. Book **High Performance Python**. \n",
      "O'Reilly. 2014. **ISBN**: 978-1-449-36159-4\n",
      "\n",
      "<a id='Avello2016'></a>\n",
      "[3] *[Avello2016]* Alexander Avello. Thesis **M\u00f3dulo QtNLP_Wordnet para la aplicaci\u00f3n QtNLP**. \n",
      "UCLV. 2016."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='alphabetic_index'></a>\n",
      "##\u00cdndice Alfab\u00e9tico##\n",
      "\n",
      "<a id='token'></a>\n",
      "**Token**: se\u00f1al, indicio, muestra. Se usa generalmente para referirse a la unidad\n",
      "m\u00e1s peque\u00f1a de procesamiento: palabras, fonemas, n-grams, etc..\n",
      "\n",
      "\n",
      "Volver al [*\u00cdndice*](#indice)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}